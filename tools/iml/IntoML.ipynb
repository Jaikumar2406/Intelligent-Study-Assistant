{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7049ce23-4ef6-4a70-b2c1-1cc2adb5a066",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from pinecone import Pinecone , ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import fitz\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.schema import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c8dcee9-f305-4bda-8723-8df55e6d8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04bc4591-a59b-4d73-a9e2-4206c6dd68fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_files = [\"Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf\" , \n",
    "             \"MachineLearningTomMitchell.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f771c2-1c7a-442a-9d7b-c4725b27fa6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf ---\n",
      "--- MachineLearningTomMitchell.pdf ---\n"
     ]
    }
   ],
   "source": [
    "text = ''\n",
    "for file in pdf_files:\n",
    "    doc = fitz.open(file)\n",
    "    print(f\"--- {file} ---\")\n",
    "    for page in doc:\n",
    "        text += page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71c1ba06-a9d2-4507-a448-1f52884b77fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Information Science and Statistics\\nSeries Editors:\\nM. Jordan\\nJ. Kleinberg\\nB. Scho¨lkopf\\nInformation Science and Statistics \\nAkaike and Kitagawa: The Practice of Time Series Analysis. \\nBishop:  Pattern Recognition and Machine Learning. \\nCowell, Dawid, Lauritzen, and Spiegelhalter: Probabilistic Networks and\\nExpert Systems. \\nDoucet, de Freitas, and Gordon: Sequential Monte Carlo Methods in Practice. \\nFine: Feedforward Neural Network Methodology. \\nHawkins and Olwell: Cumulative Sum Charts and Chart'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c729f6e1-2478-4218-9666-a39b7446402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = [text[i:i+1000] for i in range(0 , len(text) ,1000 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cb93f0-4cec-48ec-884e-a92984149159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'), β−1\\x0b\\n(1.60)\\nwhere, for consistency with the notation in later chapters, we have deﬁned a preci-\\nsion parameter β corresponding to the inverse variance of the distribution. This is\\nillustrated schematically in Figure 1.16.\\n1.2. Probability Theory\\n29\\nFigure 1.16\\nSchematic illustration of a Gaus-\\nsian conditional distribution for t given x given by\\n(1.60), in which the mean is given by the polyno-\\nmial function y(x, w), and the precision is given\\nby the parameter β, which is related to the vari-\\nance by β−1 = σ2.\\nt\\nx\\nx0\\n2σ\\ny(x0, w)\\ny(x, w)\\np(t|x0, w, β)\\nWe now use the training data {x, t} to determine the values of the unknown\\nparameters w and β by maximum likelihood. If the data are assumed to be drawn\\nindependently from the distribution (1.60), then the likelihood function is given by\\np(t|x, w, β) =\\nN\\n\\x0e\\nn=1\\nN\\n\\ntn|y(xn, w), β−1\\x0b\\n.\\n(1.61)\\nAs we did in the case of the simple Gaussian distribution earlier, it is convenient to\\nmaximize the logarithm of the likelihood function. Substitutin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59dac7f9-ac11-4c62-b3b8-e3499e32e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pine_cone = os.getenv('pine_cone')\n",
    "groq = os.getenv('groq')\n",
    "hugging_face = os.getenv(\"hugging_face\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "371613f3-a6f5-4c78-a116-8acbeda5a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings =  HuggingFaceBgeEmbeddings(model_name='BAAI/bge-base-en-v1.5',\n",
    "                                      model_kwargs={\"token\" : hugging_face})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80252d65-c7b1-4035-b2b5-5f7e1eca0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = Pinecone(api_key = pine_cone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3fd7ac-a39a-4a6a-baf3-be046676a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = \"intoductionml\"\n",
    "if index not in pc.list_indexes().names():\n",
    "    pc.create_index(name= index,\n",
    "    spec = ServerlessSpec(region=\"us-east-1\" , cloud=\"AWS\"),\n",
    "    dimension= 768,\n",
    "    metric= 'cosine',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fff904f-3e91-46ca-af9b-f7a102da735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pc.Index(name = index , host = os.getenv(\"host_bg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17445d2c-7e50-4dc3-a0ee-1d21d865a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [Document(page_content = chunks) for chunks in chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa469625-2d26-4eb3-9355-e47f8a9bdc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = PineconeVectorStore(index=index,\n",
    "    embedding=embeddings,\n",
    "    text_key=\"page_content\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0015fbca-d4b2-496f-bea7-bcd40fec4483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 88/88 [09:50<00:00,  6.71s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "batch_size = 32\n",
    "for i in tqdm(range(0, len(docs), batch_size)):\n",
    "    batch = docs[i:i+batch_size]\n",
    "    try:\n",
    "        vector.add_documents(batch)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch {i}-{i+batch_size}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "117b8cae-184e-4a3b-95f1-228bf47d526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrive = vector.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ea62bfd4-82a6-4389-85a8-359ddf19873a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0cda2617-9da4-458f-9906-7a0aca5b4a8e', metadata={}, page_content=' \\nBook Info: Presents the key algorithms and theory that form the core of machine learning. \\nDiscusses such theoretical issues as How does learning performance vary with the number of \\ntraining examples presented? and Which learning algorithms are most appropriate for various \\ntypes of learning tasks? DLC: Computer algorithms.  \\nBook Description: This book covers the field of machine learning, which is the study of \\nalgorithms that allow computer programs to automatically improve through experience. The \\nbook is intended to support upper level undergraduate and introductory level graduate courses in \\nmachine learning \\nPREFACE \\nThe field of machine learning is concerned with the question of how to construct \\ncomputer programs that automatically improve with experience. In recent years \\nmany successful machine learning applications have been developed, ranging from \\ndata-mining programs that learn to detect fraudulent credit card transactions, to \\ninformation-filtering systems that learn'),\n",
       " Document(id='ebd2f438-fa67-4e88-9fbe-0f6b6336bc8b', metadata={}, page_content='of competence and customization. And a detailed understanding of information- \\nprocessing algorithms for machine learning might lead to a better understanding \\nof human learning abilities (and disabilities) as well. \\nWe do not yet know how to make computers learn nearly as well as people \\nlearn. However, algorithms have been invented that are effective for certain types \\nof learning tasks, and a theoretical understanding of learning is beginning to \\nemerge. Many practical computer programs have been developed to exhibit use- \\nful types of learning, and significant commercial applications have begun to ap- \\npear. For problems such as speech recognition, algorithms based on machine \\nlearning outperform all other approaches that have been attempted to date. In \\nthe field known as data mining, machine learning algorithms are being used rou- \\ntinely to discover valuable knowledge from large commercial databases containing \\nequipment maintenance records, loan applications, financial transact'),\n",
       " Document(id='f57b4068-e286-49a8-b4cc-2a160ddf98f2', metadata={}, page_content='learning problem requires a well-specified task, performance \\nmetric, and source of training experience. \\n0 Designing a machine learning approach involves a number of design choices, \\nincluding choosing the type of training experience, the target function to \\nbe learned, a representation for this target function, and an algorithm for \\nlearning the target function from training examples. \\n18 \\nMACHINE LEARNING \\n0 Learning involves search: searching through a space of possible hypotheses \\nto find the hypothesis that best fits the available training examples and other \\nprior constraints or knowledge. Much of this book is organized around dif- \\nferent learning methods that search different hypothesis spaces (e.g., spaces \\ncontaining numerical functions, neural networks, decision trees, symbolic \\nrules) and around theoretical results that characterize conditions under which \\nthese search methods converge toward an optimal hypothesis. \\nThere are a number of good sources for reading about the ')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrive.invoke(\"what is machine learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3382f0-a63c-4831-b34f-4801d19974be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "genai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
